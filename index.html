<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models">
  <meta name="keywords" content="VADER, Causal Video Anomaly, Large Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VADER</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* Version 1: Clean and Modern with Soft Shadows */
    .method-image {
      border-radius: 12px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
      margin: 15px;
    }
    .teaser-image {
      margin: 15px;
    }
    .experiment-image {
      margin: 15px;
      width: 100%;
    }
    .results-table {
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 2px 15px rgba(0, 0, 0, 0.1);
    }
    .results-table th {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 15px;
      font-weight: 600;
    }
    .results-table td {
      padding: 12px 15px;
      border-bottom: 1px solid #eee;
    }
    .results-table tr:hover {
      background-color: #f8f9ff;
    }
    .qualitative-image {
      border-radius: 15px;
      box-shadow: 0 5px 25px rgba(0, 0, 0, 0.12);
      width: 100%;
      margin: 15px;
    }
    .section-card {
      background: white;
      border-radius: 16px;
      padding: 2rem;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
      margin-bottom: 2rem;
    }
    .benchmark-card {
      background: #ffffff;
      border-radius: 12px;
      padding: 1.5rem;
      margin-bottom: 1.5rem;
      box-shadow: 0 3px 15px rgba(0, 0, 0, 0.08);
    }
    .benchmark-title {
      font-weight: 600;
      margin-bottom: 1rem;
      font-size: 1.25rem;
    }
    .placeholder-img {
      background: linear-gradient(135deg, #f5f7fa 0%, #e4e8eb 100%);
      border-radius: 12px;
      height: 200px;
      display: flex;
      align-items: center;
      justify-content: center;
      color: #999;
      font-style: italic;
    }
  </style>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Ying Cheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Yu-Ho Lin</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://minhungchen.netlify.app/">Min-Hung Chen</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Fu-En Yang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.nthu.edu.tw/~lai/">Shang-Hong Lai</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National Tsing Hua University,</span>
            <span class="author-block"><sup>2</sup>NVIDIA</span>
          </div>

          <div class="is-size-5 publication-authors" style="margin-top: 0.5rem;">
            <span class="author-block" style="font-weight: 600; color: #2d5666;">WACV 2026</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2511.07299.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.07299"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/vader_teaser.png" class="teaser-image" style="width: 100%;" />
      <h2 class="subtitle has-text-centered" style="margin-top: 1.5rem;">
        <span class="dnerf">VADER</span> enables detailed anomaly understanding by extracting key visual and relational cues from selected key frames.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video anomaly understanding (VAU) aims to provide detailed interpretation and semantic comprehension of
anomalous events within videos, addressing limitations of traditional methods that focus solely on detecting and localizing anomalies. However, existing approaches often neglect the deeper causal relationships and interactions between objects, which are critical for understanding anomalous behaviors. In this paper, we propose VADER, an LLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe object Relation features with visual cues to enhance anomaly comprehension from video. Specifically, VADER first applies an Anomaly Scorer to assign per-frame anomaly scores, followed by a ContextAwarE Sampling (CAES) strategy to capture the causal context of each anomalous event. A Relation Feature Extractor and a COntrastive Relation Encoder (CORE) jointly model dynamic object interactions, producing compact relational representations for downstream reasoning. These visual and relational cues are integrated with LLMs to generate detailed, causally grounded descriptions and support robust anomaly-related question answering. Experiments on multiple real-world VAU benchmarks demonstrate that VADER achieves strong results across anomaly description, explanation, and causal reasoning tasks, advancing the frontier of explainable video anomaly analysis.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<!-- Method Overview Section -->
<section class="section" style="background-color: #fafbfc;">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Method Overview</h2>
    <div class="content has-text-centered">
      <img src="./static/images/architechture.png" class="method-image" style="width: 100%; max-width: none; margin-bottom: 1.5rem;" />
      <p class="has-text-justified" style="margin-top: 1rem;">
        Overview of our VADER framework. Given an input video, the Anomaly Scorer and Context-AwarE Sampling (CAES) identify keyframes for narrative-driven anomaly analysis. Visual and relational features are extracted and encoded, with dynamic relational patterns distilled by the COntrastive Relation Encoder (CORE). All cues are fused by a pretrained LLM for comprehensive video anomaly understanding. The right panel illustrates the relational branch, including temporal association, volatility mining, and contrastive token learning.
      </p>
    </div>
  </div>
</section>


<!-- Experiment Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experiment Results</h2>
    
    <div class="columns is-centered">
      <div class="column is-full-width">
        
        <!-- Dataset 1: HIVAU -->
        <div class="benchmark-card">
          <h3 class="benchmark-title" style="color: #2d5666;">HIVAU-70k Benchmark</h3>
          <div class="has-text-centered">
            <img src="./static/images/hivau.png" class="experiment-image" />
          </div>
        </div>

        <!-- Dataset 2: HAWK -->
        <div class="benchmark-card">
          <h3 class="benchmark-title" style="color: #2d5666;">HAWK Benchmark</h3>
          <div class="has-text-centered">
            <img src="./static/images/hawk.png" class="experiment-image" />
          </div>
        </div>

      </div>
    </div>
  </div>
</section>


<!-- Qualitative Results Section -->
<section class="section" style="background-color: #fafbfc;">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Qualitative Results</h2>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="content has-text-centered">
          
          <p class="has-text-justified" style="margin-top: 1.5rem; max-width: 900px; margin-left: auto; margin-right: auto;">
            The descriptions generated by Otter and Video-ChatGPT contain hallucination or incorrect analysis. In contrast, VADER produces concise, contextually grounded, and causally coherent descriptions that accurately reflect the events and their underlying dynamics across various challenging cases.
          </p>
          <img src="./static/images/Visualization_Compare.png" class="qualitative-image" />
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{cheng2025vadercausalvideoanomaly,
      title={VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models}, 
      author={Ying Cheng and Yu-Ho Lin and Min-Hung Chen and Fu-En Yang and Shang-Hong Lai},
      year={2025},
      eprint={2511.07299},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2511.07299}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
